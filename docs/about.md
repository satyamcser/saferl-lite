# 🙌 About SafeRL-Lite

**SafeRL-Lite** is a lightweight, explainable, and modular Python library for constrained reinforcement learning (Safe RL). It is designed for researchers, educators, and engineers who want to build safe, interpretable agents in Gym-compatible environments with minimal setup.

---

## 🎯 Mission

SafeRL-Lite aims to:
- Enable **constrained RL** with built-in safety logic.
- Support **real-time explainability** using SHAP and saliency maps.
- Provide **modular components** for easy experimentation and extension.
- Be **minimal**, **readable**, and **production-friendly**.

---

## 🧱 Key Components

- **Constrained DQN agent** with runtime violation tracking.
- **Environment wrappers** for safety constraints and logging.
- **Evaluation module** to track rewards, constraint violations, and success metrics.
- **Explainability tools**:
  - Gradient-based **saliency maps**
  - **SHAP** values for input importance

---

## 👩‍🔬 Who Should Use This?

SafeRL-Lite is ideal for:
- 📚 **Educators** teaching RL and safety concepts.
- 🔬 **Researchers** in safe RL, explainable AI (XAI), or constrained optimization.
- 🧪 **Experimenters** building proof-of-concepts for safety-critical environments (e.g., healthcare, robotics).

---

## 🛠️ Design Philosophy

- ✅ Simplicity over complexity  
- 🧩 Component reusability  
- 🔍 Built-in explainability  
- 🧪 Test-driven development  
- 📦 PyPI-ready structure  

---

## 🤝 Contributing

We welcome contributions from the community! Check out the [CONTRIBUTING.md](https://github.com/satyamcser/saferl-lite/blob/main/CONTRIBUTING.md) for guidelines.

---

## 📜 License

This project is licensed under the **MIT License**. See the [LICENSE](https://github.com/satyamcser/saferl-lite/blob/main/LICENSE) file for details.

---

## 🌐 Links

- GitHub: [https://github.com/satyamcser/saferl-lite](https://github.com/satyamcser/saferl-lite)
- PyPI: *Coming soon*
- Docs: *This site*

---