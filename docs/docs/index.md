# SafeRL-Lite

Welcome to **SafeRL-Lite**, a lightweight, explainable, and constrained reinforcement learning library built in Python.

---

## âœ¨ Features

- â™»ï¸ **Constrained Agents**: Supports safe training using budgeted penalties and constraint wrappers.
- ğŸ” **Explainability Tools**: Includes SHAP and saliency-based attribution methods.
- ğŸ® **Custom Environments**: Easy wrappers for constraint-aware OpenAI Gym environments.
- ğŸ“Š **Evaluation Metrics**: Regret, safe episode rate, violation count.
- ğŸ§ª **Tested and Documented**: Full unit test suite with CI + MkDocs support.

---

## ğŸ”§ Repository Info

- **Author**: [Satyam Mishra](https://github.com/satyamcser)
- **GitHub**: [github.com/satyamcser/saferl-lite](https://github.com/satyamcser/saferl-lite)

---

## ğŸ“¦ Installation

See [Usage â†’ Installation](usage/installation.md) for details.

## ğŸš€ Quickstart

See [Usage â†’ Quickstart](usage/quickstart.md) to get up and running in 60 seconds.

## ğŸ§ª Example

- [CartPole with Constraints](examples/cartpole.md)
